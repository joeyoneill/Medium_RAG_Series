{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env File for OpenAI API Key\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Get Embeddings Model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Initialize ChromaDB as Vector Store\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"test_collection\",\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Read in State of the Union Address File\n",
    "with open(\"../RAG_Docs/2024_state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "\n",
    "# Initialize Text Splitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Create Documents (Chunks) From File\n",
    "texts = text_splitter.create_documents([state_of_the_union])\n",
    "\n",
    "# Save Document Chunks to Vector Store\n",
    "ids = vector_store.add_documents(texts)\n",
    "\n",
    "# Set Chroma as the Retriever\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* And yes, my purpose tonight is to both wake up this Congress, and alert the American people that this is no ordinary moment either. \n",
      "\n",
      "Not since President Lincoln and the Civil War have freedom and democracy been under assault here at home as they are today. \n",
      "\n",
      "What makes our moment rare is that freedom and democracy are under attack, both at home and overseas, at the very same time. \n",
      "\n",
      "Overseas, Putin of Russia is on the march, invading Ukraine and sowing chaos throughout Europe and beyond. \n",
      "\n",
      "If anybody in this room thinks Putin will stop at Ukraine, I assure you, he will not. \n",
      "\n",
      "But Ukraine can stop Putin if we stand with Ukraine and provide the weapons it needs to defend itself. That is all Ukraine is asking. They are not asking for American soldiers. \n",
      "\n",
      "In fact, there are no American soldiers at war in Ukraine. And I am determined to keep it that way. \n",
      "\n",
      "But now assistance for Ukraine is being blocked by those who want us to walk away from our leadership in the world. [{}]\n",
      "\n",
      "\n",
      "* But now assistance for Ukraine is being blocked by those who want us to walk away from our leadership in the world. \n",
      "\n",
      "It wasn’t that long ago when a Republican President, Ronald Reagan, thundered, “Mr. Gorbachev, tear down this wall.” \n",
      "\n",
      "Now, my predecessor, a former Republican President, tells Putin, “Do whatever the hell you want.” \n",
      "\n",
      "A former American President actually said that, bowing down to a Russian leader. \n",
      "\n",
      "It’s outrageous. It’s dangerous. It’s unacceptable. \n",
      "\n",
      "America is a founding member of NATO the military alliance of democratic nations created after World War II to prevent war and keep the peace.  \n",
      "\n",
      "Today, we’ve made NATO stronger than ever. \n",
      "\n",
      "We welcomed Finland to the Alliance last year, and just this morning, Sweden officially joined NATO, and their Prime Minister is here tonight. \n",
      "\n",
      "Mr. Prime Minister, welcome to NATO, the strongest military alliance the world has ever known. [{}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the Vector Store to Check Population\n",
    "results = vector_store.similarity_search(\n",
    "    'Who invaded Ukraine?',\n",
    "    k=2\n",
    ")\n",
    "\n",
    "# Print Resulting Chunks\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanved RAG: Pre-retrieval Query Rewrting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Pre-retrieval Query Rewriting Function\n",
    "def query_rewrite(query: str, llm: ChatOpenAI):\n",
    "\n",
    "    # Rewritten Query Prompt\n",
    "    query_rewrite_prompt = f\"You are a helpful assistant that takes a user's query and turns it into a short statement or paragraph so that it can be used in a semantic similarity search on a vector database to return the most similar chunks of content based on the rewritten query. Please make no comments, just return the rewritten query.\\n\\nquery: {query}\\n\\nai: \"\n",
    "\n",
    "    # Invoke LLM\n",
    "    retrieval_query = llm.invoke(query_rewrite_prompt)\n",
    "\n",
    "    # Return Generated Retrieval Query\n",
    "    return retrieval_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced RAG: Post-retrieval Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "\n",
    "# Flash Rerank Compressor for Post-retrieval Rerank\n",
    "compressor = FlashrankRerank()\n",
    "\n",
    "# Update Retriever -> Compression Retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Document Parsing Function to String\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RAG Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Prompt Template\n",
    "prompt_template = \"\"\"Use the context provided to answer the user's question below. If you do not know the answer based on the context provided, tell the user that you do not know the answer to their question based on the context provided and that you are sorry.\n",
    "context: {context}\n",
    "\n",
    "question: {query}\n",
    "\n",
    "answer: \"\"\"\n",
    "\n",
    "# Create Prompt Instance from template\n",
    "custom_rag_prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM instance\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom RAG Chain Class\n",
    "class RAGChain:\n",
    "\n",
    "    # Chain Constructor\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: ChatOpenAI,\n",
    "        retriever: ContextualCompressionRetriever,\n",
    "        prompt: PromptTemplate\n",
    "    ):\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "        self.prompt = prompt\n",
    "    \n",
    "    # Run Chain Function - same naming convention as LangChain\n",
    "    def invoke(self, query: str):\n",
    "\n",
    "        # Advanced RAG: Pre-retrieval Query Rewrite\n",
    "        retrieval_query = query_rewrite(query, self.llm)\n",
    "        \n",
    "        # Retrieval w/ Post-retrieval Reranking\n",
    "        docs = self.retriever.invoke(retrieval_query.content)\n",
    "\n",
    "        # Format Docs for Context String\n",
    "        context = format_docs(docs)\n",
    "\n",
    "        # Prompt Template\n",
    "        final_prompt = self.prompt.format(context=context, query=query)\n",
    "\n",
    "        # LLM Invoke\n",
    "        return llm.invoke(final_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the 2024 State of the Union address, President Joe Biden stated that Putin of Russia invaded Ukraine. This is considered wrong because it is an assault on freedom and democracy, and it poses a threat not only to Ukraine but also to peace and stability in Europe and beyond. Biden emphasized the need to stand with Ukraine and provide the necessary assistance to defend itself against this aggression.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Custom RAG Chain\n",
    "rag_chain = RAGChain(llm, compression_retriever, custom_rag_prompt)\n",
    "\n",
    "# Invoke the chain\n",
    "response = rag_chain.invoke('According to the 2024 state of the union address, Who invaded Ukraine and why is this wrong?')\n",
    "\n",
    "# Print Output\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I do not know the answer to your question based on the context provided.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain\n",
    "response = rag_chain.invoke('What is 2+2?')\n",
    "\n",
    "# Print Output\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
